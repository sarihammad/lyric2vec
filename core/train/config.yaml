# Lyric2Vec Training Configuration

# Data paths
data:
  raw_path: "data/raw"
  processed_path: "data/processed"
  artifacts_path: "data/artifacts"
  manifest_path: "data/raw/manifest.csv"

  # Dataset splits
  train_split: 0.8
  val_split: 0.1
  test_split: 0.1
  max_samples: null # null for all samples

# Model configuration
model:
  # Text encoder
  hf_text_model: "distilbert-base-uncased"
  text_dim: 768

  # Audio encoder
  audio_sr: 16000
  n_fft: 2048
  hop_length: 512
  n_mels: 128
  audio_dim: 256

  # Metadata encoder
  meta_dim: 64

  # Fusion
  fusion_type: "gated" # weighted_sum, gated, attention, cross_modal
  d: 256 # Final embedding dimension

  # Loss weights [text-audio, text-meta, audio-meta]
  loss_weights: [1.0, 0.5, 0.2]
  temperature: 0.07
  triplet_margin: 0.2

# Training configuration
training:
  batch_size: 32
  num_workers: 4
  pin_memory: true

  # Optimization
  learning_rate: 1e-4
  weight_decay: 1e-5
  num_epochs: 10

  # Training features
  fp16: true
  gradient_clip_val: 1.0

  # Validation
  val_check_interval: 0.5 # Validate every 50% of epoch
  save_top_k: 3
  monitor: "val_loss"
  mode: "min"

# Ray configuration
ray:
  num_workers: 4
  use_gpu: false
  resources_per_worker:
    cpu: 2
    memory: 4000000000 # 4GB
    gpu: 0 # Set to 1 if using GPU

# Logging
logging:
  level: "INFO"
  log_every_n_steps: 10
  save_dir: "logs"

# Checkpointing
checkpointing:
  save_dir: "checkpoints"
  filename: "lyric2vec-{epoch:02d}-{val_loss:.2f}"
  save_last: true
  save_top_k: 3
